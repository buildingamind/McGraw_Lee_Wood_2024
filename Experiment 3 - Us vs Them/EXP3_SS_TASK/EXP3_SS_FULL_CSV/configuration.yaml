default_settings:
  trainer_type: ppo
  hyperparameters:
    batch_size: 256
    buffer_size: 2048
    learning_rate: 0.0003
    beta: 0.01
    epsilon: 0.2
    lambd: 0.95
    num_epoch: 3
    shared_critic: false
    learning_rate_schedule: linear
    beta_schedule: linear
    epsilon_schedule: linear
  network_settings:
    normalize: false
    hidden_units: 512
    num_layers: 2
    vis_encode_type: simple
    memory: null
    goal_conditioning_type: hyper
    deterministic: false
  reward_signals:
    curiosity:
      gamma: 0.99
      strength: 1.0
      network_settings:
        normalize: false
        hidden_units: 128
        num_layers: 1
        vis_encode_type: simple
        memory: null
        goal_conditioning_type: hyper
        deterministic: false
      learning_rate: 0.0003
      encoding_size: null
  init_path: null
  keep_checkpoints: 5
  checkpoint_interval: 10000
  max_steps: 1000000
  time_horizon: 128
  summary_freq: 1000
  threaded: false
  self_play: null
  behavioral_cloning: null
env_settings:
  env_path: "C:/Users/Sceni/Desktop/AnimalVR Builds/Windows/UvsT Replication Study/TrainConditions/2AloneAgents/TwinSimulations.exe"
  env_args:
  - --cam-frequency=0
  - --steps=3000
  - --displays=0
  - --fov=160
  - --id=2AloneAgents
  base_port: 5006
  num_envs: 1
  num_areas: 1
  seed: 1
engine_settings:
  width: 80
  height: 80
  quality_level: 5
  time_scale: 20.0
  target_frame_rate: -1
  capture_frame_rate: 300
  no_graphics: false
environment_parameters: null
checkpoint_settings:
  run_id: 2AloneAgents
  initialize_from: null
  load_model: false
  resume: false
  force: false
  train_model: false
  inference: false
  results_dir: results
torch_settings:
  device: cuda
debug: false
